<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Anne Bernard">
<meta name="dcterms.date" content="2023-09-14">

<title>TP1 - knn</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="TP1-knn_files/libs/clipboard/clipboard.min.js"></script>
<script src="TP1-knn_files/libs/quarto-html/quarto.js"></script>
<script src="TP1-knn_files/libs/quarto-html/popper.min.js"></script>
<script src="TP1-knn_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="TP1-knn_files/libs/quarto-html/anchor.min.js"></script>
<link href="TP1-knn_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="TP1-knn_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="TP1-knn_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="TP1-knn_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="TP1-knn_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">TP1 - knn</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Anne Bernard </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 14, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sommaire</h2>
   
  <ul>
  <li><a href="#rappels-de-classification" id="toc-rappels-de-classification" class="nav-link active" data-scroll-target="#rappels-de-classification">Rappels de classification</a>
  <ul class="collapse">
  <li><a href="#généralisation-artificielle-de-données" id="toc-généralisation-artificielle-de-données" class="nav-link" data-scroll-target="#généralisation-artificielle-de-données">Généralisation artificielle de données </a><a name="Généralisation artificielle de données" class="nav-link" data-scroll-target="undefined" href=""></a>
  <ul class="collapse">
  <li><a href="#question-1" id="toc-question-1" class="nav-link" data-scroll-target="#question-1">Question 1 </a><a name="Question 1" class="nav-link" data-scroll-target="undefined" href=""></a></li>
  </ul></li>
  </ul></li>
  <li><a href="#la-méthode-des-k-plus-prohces-voisins" id="toc-la-méthode-des-k-plus-prohces-voisins" class="nav-link" data-scroll-target="#la-méthode-des-k-plus-prohces-voisins">La méthode des k-plus prohces voisins</a>
  <ul class="collapse">
  <li><a href="#approche-intuitive" id="toc-approche-intuitive" class="nav-link" data-scroll-target="#approche-intuitive">Approche intuitive</a>
  <ul class="collapse">
  <li><a href="#question-1-1" id="toc-question-1-1" class="nav-link" data-scroll-target="#question-1-1">Question 1</a></li>
  </ul></li>
  <li><a href="#approche-formelle" id="toc-approche-formelle" class="nav-link" data-scroll-target="#approche-formelle">Approche formelle</a>
  <ul class="collapse">
  <li><a href="#question-2" id="toc-question-2" class="nav-link" data-scroll-target="#question-2">Question 2</a></li>
  <li><a href="#question-3" id="toc-question-3" class="nav-link" data-scroll-target="#question-3">Question 3</a></li>
  <li><a href="#question-4" id="toc-question-4" class="nav-link" data-scroll-target="#question-4">Question 4</a></li>
  <li><a href="#question-5" id="toc-question-5" class="nav-link" data-scroll-target="#question-5">Question 5</a></li>
  <li><a href="#question-6" id="toc-question-6" class="nav-link" data-scroll-target="#question-6">Question 6</a></li>
  <li><a href="#question-7" id="toc-question-7" class="nav-link" data-scroll-target="#question-7">Question 7</a></li>
  <li><a href="#question-8" id="toc-question-8" class="nav-link" data-scroll-target="#question-8">Question 8</a></li>
  <li><a href="#question-9" id="toc-question-9" class="nav-link" data-scroll-target="#question-9">Question 9</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="rappels-de-classification" class="level1">
<h1>Rappels de classification</h1>
<section id="généralisation-artificielle-de-données" class="level2">
<h2 class="anchored" data-anchor-id="généralisation-artificielle-de-données">Généralisation artificielle de données <a name="Généralisation artificielle de données" href=""></a></h2>
<section id="question-1" class="level3">
<h3 class="anchored" data-anchor-id="question-1">Question 1 <a name="Question 1" href=""></a></h3>
<p><code>rand_gauss</code> : La fonction <code>rand_gauss</code> génère des points échantillonnés à partir d’une variable gaussienne de taille 2 centrée réduite. Elle prend en paramètres le nombre d’échantillons <span class="math inline">\(n=100\)</span>, la moyenne <span class="math inline">\(\mu=[1,1]\)</span> et l’écart-type <span class="math inline">\(\sigma=[\sqrt{0.1},\sqrt{0.1}]\)</span>. Elle retourne un tableau avec la variable gaussienne de moyenne <span class="math inline">\(\mu=[1,1]\)</span> et d’écart-type <span class="math inline">\(\sigma=[\sqrt{0.1},\sqrt{0.1}]\)</span>.</p>
<p><code>rand_bi_gauss</code> : La fonction <code>rand_bi_gauss</code> génère grâce à <code>rand_gauss</code> deux variables gaussiennes d’échantillons <span class="math inline">\(n_1=100\)</span> et <span class="math inline">\(n_2=100\)</span>, de moyennes et d’écart-types respectifs : <span class="math inline">\(\mu_1=[1,1], \, \mu_2=[-1,-1]\)</span>, <span class="math inline">\(\sigma_1=[0.1,0.1]=\sigma_2\)</span>. Elle crée le vecteur <span class="math inline">\(y\)</span> des réponses en empilant <span class="math inline">\(n_1\)</span> <span class="math inline">\(1\)</span> puis <span class="math inline">\(n_2\)</span> <span class="math inline">\(-1\)</span>. Elle combine aussi les échantillons dans <span class="math inline">\(X\)</span>. Et ensuite elle permute aléatoirement les indices et renvoie les échantillons et les réponses.</p>
<p><code>rand_tri_gauss</code> : La fonction <code>rand_tri_gauss</code> utilise la fonction <code>rand_gauss</code>comme précédemment pour générer les échantillons de chaque distribution. Les échantillons générés sont ensuite empilés verticalement dans la matrice X, et les réponses correspondantes sont stockées dans le vecteur y. Ensuite les indices des échantillons sont permutés de manière aléatoire, et les échantillons et les réponses sont réorganisés en fonction de ces indices avant d’être renvoyés.</p>
<p><code>rand_clown</code>: La fonction <code>rand_clown</code> commence par générer des échantillons aléatoires à partir d’une distribution gaussienne en utilisant <code>np.random.randn</code>. Les échantillons générés sont stockés dans x0, x1 et x2. Ensuite, la fonction ajoute du bruit aux échantillons du premier groupe de données en multipliant x0 par lui-même et en ajoutant le bruit généré par np.random.randn(n1, 1). Le résultat est stocké dans x1. Pour le deuxième groupe de données, la fonction génère deux ensembles de bruit à l’aide de np.random.randn(n2, 1) et les combine avec sigma2 pour obtenir des valeurs différentes. Ces deux ensembles de bruit sont ensuite concaténés horizontalement à l’aide de np.hstack pour obtenir x2. Enfin, les échantillons des trois groupes sont empilés verticalement en utilisant np.vstack pour obtenir la matrice X. Les réponses sont générées en empilant horizontalement n1 réponses 1 suivies de n2 réponses -1. Les indices des échantillons sont permutés aléatoirement à l’aide de <code>np.random.permutation</code>, et les échantillons et les réponses sont réorganisés en fonction de ces indices avant d’être renvoyés.</p>
<p><code>rand_checkers</code>: La fonction rand_checkers génère un damier aléatoire : à partir d’une distribution uniforme, on génère un damier dans la partie surpérieure droite du plan. La structure en damier n’est pas flagrante lorsque le nombre de points générés est petit mais elle devient évidente pour 1000 points.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, ClassifierMixin</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats  <span class="co"># to use scipy.stats.mode</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> neighbors</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tp_knn_source <span class="im">import</span> (rand_gauss, rand_bi_gauss, rand_tri_gauss,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                               rand_checkers, rand_clown, plot_2d, ErrorCurve,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>                               frontiere, LOOCurve)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> rc</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>plt.close(<span class="st">'all'</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>rc(<span class="st">'font'</span>, <span class="op">**</span>{<span class="st">'family'</span>: <span class="st">'sans-serif'</span>, <span class="st">'sans-serif'</span>: [<span class="st">'Computer Modern Roman'</span>]})</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {<span class="st">'axes.labelsize'</span>: <span class="dv">12</span>,</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>          <span class="st">'font.size'</span>: <span class="dv">16</span>,</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>          <span class="st">'legend.fontsize'</span>: <span class="dv">16</span>,</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>          <span class="st">'text.usetex'</span>: <span class="va">False</span>,</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>          <span class="st">'figure.figsize'</span>: (<span class="dv">8</span>, <span class="dv">6</span>)}</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>plt.rcParams.update(params)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>sns.set_context(<span class="st">"poster"</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>sns.set_palette(<span class="st">"colorblind"</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"white"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)  <span class="co"># fix seed globally</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> [<span class="fl">1.</span>, <span class="fl">1.</span>]</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> [<span class="fl">1.</span>, <span class="fl">1.</span>]</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>rand_gauss(n, mu, sigma)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>n1 <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>n2 <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>mu1 <span class="op">=</span> [<span class="fl">1.</span>, <span class="fl">1.</span>]</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>mu2 <span class="op">=</span> [<span class="op">-</span><span class="fl">1.</span>, <span class="op">-</span><span class="fl">1.</span>]</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>sigma1 <span class="op">=</span> [<span class="fl">0.9</span>, <span class="fl">0.9</span>]</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="op">=</span> [<span class="fl">0.9</span>, <span class="fl">0.9</span>]</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>X1, y1 <span class="op">=</span> rand_bi_gauss(n1, n2, mu1, mu2, sigma1, sigma2)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>n1 <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>n2 <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>n3 <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>mu1 <span class="op">=</span> [<span class="fl">1.</span>, <span class="fl">1.</span>]</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>mu2 <span class="op">=</span> [<span class="op">-</span><span class="fl">1.</span>, <span class="op">-</span><span class="fl">1.</span>]</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>mu3 <span class="op">=</span> [<span class="fl">1.</span>, <span class="op">-</span><span class="fl">1.</span>]</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>sigma1 <span class="op">=</span> [<span class="fl">0.9</span>, <span class="fl">0.9</span>]</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="op">=</span> [<span class="fl">0.9</span>, <span class="fl">0.9</span>]</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>sigma3 <span class="op">=</span> [<span class="fl">0.9</span>, <span class="fl">0.9</span>]</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>X2, y2 <span class="op">=</span> rand_tri_gauss(n1, n2, n3, mu1, mu2, mu3, sigma1, sigma2, sigma3)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>n1 <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>n2 <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>sigma1 <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>X3, y3 <span class="op">=</span> rand_clown(n1, n2, sigma1, sigma2)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>n1 <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>n2 <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>X4, y4 <span class="op">=</span> rand_checkers(n1, n2, sigma)</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>plt.close(<span class="st">"all"</span>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>plt.ion()</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">141</span>)</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'First data set'</span>)</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>plot_2d(X1, y1)</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">142</span>)</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Second data set'</span>)</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>plot_2d(X2, y2)</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">143</span>)</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Third data set'</span>)</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>plot_2d(X3, y3)</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">144</span>)</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Fourth data set'</span>)</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>plot_2d(X4, y4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="TP1-knn_files/figure-html/cell-3-output-1.png" width="1194" height="467"></p>
</div>
</div>
</section>
</section>
</section>
<section id="la-méthode-des-k-plus-prohces-voisins" class="level1">
<h1>La méthode des k-plus prohces voisins</h1>
<section id="approche-intuitive" class="level2">
<h2 class="anchored" data-anchor-id="approche-intuitive">Approche intuitive</h2>
<p><a name="Approche intuitive" href=""></a></p>
<section id="question-1-1" class="level3">
<h3 class="anchored" data-anchor-id="question-1-1">Question 1</h3>
<p><a name="Question 1" href=""></a></p>
<p>La méthode que l’on pourrait utiliser est la suivante : on pourrait faire la moyenne des k plus proches voisins pour obtenir une valeur approchée de notre point, bien que nous ne pourrions pas tomber sur la valeur exacte. Ce n’est pas aussi ‘simple’ qu’avec des classes de nombres entiers.</p>
</section>
</section>
<section id="approche-formelle" class="level2">
<h2 class="anchored" data-anchor-id="approche-formelle">Approche formelle</h2>
<p><a name="Approche formelle" href=""></a></p>
<section id="question-2" class="level3">
<h3 class="anchored" data-anchor-id="question-2">Question 2</h3>
<p><a name="Question 2" href=""></a></p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> KNNClassifier(BaseEstimator, ClassifierMixin):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Home made KNN Classifier class."""</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_neighbors<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_neighbors <span class="op">=</span> n_neighbors</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_ <span class="op">=</span> X</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_ <span class="op">=</span> y</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sauvegarde les données d'entrainement</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        dist <span class="op">=</span> np.<span class="bu">sum</span>((X[:, np.newaxis, :]<span class="op">-</span><span class="va">self</span>.X_[np.newaxis, :, :])<span class="op">**</span><span class="dv">2</span>,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>                      axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        idx_sort <span class="op">=</span> np.argsort(dist, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># on récupère les indices par rapport aux valeurs des distances</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        idx_neighbors <span class="op">=</span> idx_sort[:, :<span class="va">self</span>.n_neighbors]</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        y_neighbors <span class="op">=</span> <span class="va">self</span>.y_[idx_neighbors]</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># on trouve les labels des voisins</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        mode, _ <span class="op">=</span> stats.mode(y_neighbors, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> np.asarray(mode.ravel(), dtype<span class="op">=</span>np.intp)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Après avoir compléter le code, nous pouvons vérifier si cette méthode est identique ou non à celle de <code>scikit-learn</code>.</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X2[::<span class="dv">2</span>]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>Y_train <span class="op">=</span> y2[::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X2[<span class="dv">1</span>::<span class="dv">2</span>]</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>Y_test <span class="op">=</span> y2[<span class="dv">1</span>::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># on utilise la classe KNNClassifier avec 10 voisins</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNNClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, Y_train)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># on utilise la classe KNeighborsClassifier avec 10 voisins</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>knn2 <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>knn2.fit(X_train, Y_train)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>y_pred2 <span class="op">=</span> knn2.predict(X_test)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># comparaison des deux</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(metrics.accuracy_score(Y_test, y_pred))</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(metrics.accuracy_score(Y_test, y_pred2))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0.8133333333333334
0.8133333333333334</code></pre>
</div>
</div>
<p>Les résultats de précisions sont les mêmes pour les deux classes donc elles sont équivalentes.</p>
</section>
<section id="question-3" class="level3">
<h3 class="anchored" data-anchor-id="question-3">Question 3</h3>
<p><a name="Question 3" href=""></a></p>
<p>En utilisant la méthode de <code>scikit-learn</code>, nous allons comparer 3 jeux de données, avec la distance euclidienne <span class="math inline">\(d(x,v)=||x-v||^2\)</span></p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>n_neighbors <span class="op">=</span> <span class="dv">5</span>  <span class="co"># the k in k-NN</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span>n_neighbors)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># for data in [data1, data2, data3, data4]:</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> X, y <span class="kw">in</span> [(X1, y1), (X2, y2), (X3, y3), (X4, y4)]:</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    knn.fit(X, y)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    plt.figure()</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    n_labels <span class="op">=</span> np.unique(y).shape[<span class="dv">0</span>]</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    frontiere(knn, X, y, w<span class="op">=</span><span class="va">None</span>, step<span class="op">=</span><span class="dv">50</span>, alpha_choice<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>              n_labels<span class="op">=</span>n_labels, n_neighbors<span class="op">=</span>n_neighbors)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    plt.draw()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<figure style="center" class="figure">
<img src="image/output1.png" width="500" height="450" class="figure-img"> <img src="image/output2.png" width="500" height="450" class="figure-img"> <img src="image/output3.png" width="500" height="450" class="figure-img"> <img src="image/output4.png" width="500" height="450" class="figure-img">
</figure>
</section>
<section id="question-4" class="level3">
<h3 class="anchored" data-anchor-id="question-4">Question 4</h3>
<p><a name="Question 4" href=""></a></p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">3</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>plot_2d(X_train, Y_train)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Samples'</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> plt.gca()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>ax.get_yaxis().set_ticks([])</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>ax.get_xaxis().set_ticks([])</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_neighbors <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co"> : fit the knn</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    knn <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span>n_neighbors)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    knn.fit(X_train, Y_train)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">5</span> <span class="op">+</span> n_neighbors)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'KNN with k=</span><span class="sc">%d</span><span class="st">'</span> <span class="op">%</span> n_neighbors)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    n_labels <span class="op">=</span> np.unique(y).shape[<span class="dv">0</span>]</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    frontiere(knn, X, y, w<span class="op">=</span><span class="va">None</span>, step<span class="op">=</span><span class="dv">50</span>, alpha_choice<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>              n_labels<span class="op">=</span>n_labels, colorbar<span class="op">=</span><span class="va">False</span>, samples<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>              n_neighbors<span class="op">=</span>n_neighbors)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>plt.draw()  <span class="co"># update plot</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="TP1-knn_files/figure-html/cell-7-output-1.png" width="1078" height="729"></p>
</div>
</div>
<p>Lorsque l’on modifie les valeurs de <span class="math inline">\(k\)</span> on s’aperçoit d’un changement important. En effet, plus le nombre de voisins est important plus les frontières sont nettes et simples. Lorsque <span class="math inline">\(k=1\)</span> la frontière est très complexe, en effet le classifieur est sensible au bruit, il ne se base que sur le plus proche et donc n’est pas fiable. Il surapprend. Si le nombre est trop grand, par exemple si <span class="math inline">\(k=n\)</span>, on va utiliser tous les points et donc le classifieur n’apporte aucune information, une seule classe sera donnée pour chaque point (la classe la plus nombreuse).</p>
</section>
<section id="question-5" class="level3">
<h3 class="anchored" data-anchor-id="question-5">Question 5</h3>
<p><a name="Question 5" href=""></a></p>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># taux d'erreur sur les données d'apprentissage</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X2[::<span class="dv">2</span>]</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>Y_train <span class="op">=</span> y2[::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X2[<span class="dv">1</span>::<span class="dv">2</span>]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>Y_test <span class="op">=</span> y2[<span class="dv">1</span>::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, Y_train)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> knn.predict(X_train)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>y_predtest <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="dv">1</span><span class="op">-</span>metrics.accuracy_score(Y_train, y_pred))</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="dv">1</span><span class="op">-</span>metrics.accuracy_score(Y_test, y_predtest))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0.0
0.18666666666666665</code></pre>
</div>
</div>
<p>On remarque que le taux d’erreur sur les données d’apprentissage lorsque <span class="math inline">\(k=1\)</span> est nul. C’est normal car l’on prend le plus proche voisin du point qui est lui-même donc on trouve la bonne classe. Le taux d’erreur sur les données de test lorsque <span class="math inline">\(k=1\)</span> est d’environ <span class="math inline">\(0.19\)</span> ce qui peut être amélioré. En effet lorsqu’on prend juste un voisin pour tester un point il est quand même probable que le plus proche ne soit pas de la même classe. Ce n’est pas assez significatif, il faut prendre plus de voisins.</p>
<p>On peut également utiliser la fonction <code>.score</code> de <code>scikit-learn</code> : <code>1-knn.score(X_train, Y_train)</code> pour les données d’entrainements. On obtient les mêmes résultats.</p>
</section>
<section id="question-6" class="level3">
<h3 class="anchored" data-anchor-id="question-6">Question 6</h3>
<p><a name="Question 6" href=""></a></p>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> (<span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> []</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> N:</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  sigma <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  data4, rep4 <span class="op">=</span> rand_checkers(i, i, sigma)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  X_train <span class="op">=</span> data4[::<span class="dv">2</span>]</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  Y_train <span class="op">=</span> rep4[::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  X_test <span class="op">=</span> data4[<span class="dv">1</span>::<span class="dv">2</span>]</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  Y_test <span class="op">=</span> rep4[<span class="dv">1</span>::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  EC <span class="op">=</span> ErrorCurve(k_range<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">50</span>, <span class="dv">1</span>)))</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  EC.fit_curve(X_train, Y_train, X_test, Y_test)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>  EC.plot()</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>  kmin <span class="op">=</span> np.argmin(EC.errors)<span class="op">+</span><span class="dv">1</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>  K.append(kmin)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>K</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>[7, 29, 8]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TP1-knn_files/figure-html/cell-9-output-2.png" width="711" height="577"></p>
</div>
</div>
<p>On obtient des valeurs de <span class="math inline">\(k\)</span> différentes.</p>
</section>
<section id="question-7" class="level3">
<h3 class="anchored" data-anchor-id="question-7">Question 7</h3>
<p><a name="Question 7" href=""></a></p>
<p>C’est plutôt long en temps de calcul car il faut calculer les distances pour chaque point. En grande dimension, les points sont de plus en plus loin et donc ils ne sont plus tellement “voisins”.</p>
</section>
<section id="question-8" class="level3">
<h3 class="anchored" data-anchor-id="question-8">Question 8</h3>
<p><a name="Question 8" href=""></a></p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The digits dataset</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> datasets.load_digits()</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(digits))</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># plot some images to observe the data</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index, (img, label) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">list</span>(<span class="bu">zip</span>(digits.images, digits.target))</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>                                     [<span class="dv">10</span>:<span class="dv">20</span>]):</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>, index <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img, cmap<span class="op">=</span>plt.cm.gray_r, interpolation<span class="op">=</span><span class="st">'None'</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'</span><span class="sc">%i</span><span class="st">'</span> <span class="op">%</span> label)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>plt.draw()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'sklearn.utils._bunch.Bunch'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TP1-knn_files/figure-html/cell-10-output-2.png" width="614" height="395"></p>
</div>
</div>
<p>On regarde les images du dataset. Il s’agit d’images de chiffres de 0 à 9 très pixellisés. On applique ensuite la méthode vue précédemment pour classifier ces images.</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="bu">len</span>(digits.data)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>X_digits_train <span class="op">=</span> digits.data[:n_samples <span class="op">//</span> <span class="dv">2</span>]</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>Y_digits_train <span class="op">=</span> digits.target[:n_samples <span class="op">//</span> <span class="dv">2</span>]</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>X_digits_test <span class="op">=</span> digits.data[n_samples <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>Y_digits_test <span class="op">=</span> digits.target[n_samples <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>knn.fit(X_digits_train, Y_digits_train)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> knn.score(X_digits_test, Y_digits_test)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>Y_digits_pred <span class="op">=</span> knn.predict(X_digits_test)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Score : </span><span class="sc">%s</span><span class="st">'</span> <span class="op">%</span> score)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Score : 0.9254727474972191</code></pre>
</div>
</div>
<p>Après avoir classifier grâce à <code>scikit-learn</code>, on obtient une précision assez élevé de <span class="math inline">\(0.925\)</span>. On a donc à peine <span class="math inline">\(8\%\)</span> d’erreur.</p>
</section>
<section id="question-9" class="level3">
<h3 class="anchored" data-anchor-id="question-9">Question 9</h3>
<p><a name="Question 9" href=""></a></p>
<p>Soit <span class="math inline">\((\mathbb{P}\{Y=i, C_k(X)=j\})_{i,j}\)</span> est la matrice de confusion associée au classifieur <span class="math inline">\(C_k\)</span> obtenu.</p>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>X_digits_train <span class="op">=</span> digits.data[:n_samples <span class="op">//</span> <span class="dv">2</span>]</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>Y_digits_train <span class="op">=</span> digits.target[:n_samples <span class="op">//</span> <span class="dv">2</span>]</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>X_digits_test <span class="op">=</span> digits.data[n_samples <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>Y_digits_test <span class="op">=</span> digits.target[n_samples <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>knn.fit(X_digits_train, Y_digits_train)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>Y_pred <span class="op">=</span> knn.predict(X_digits_test)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>CM <span class="op">=</span> metrics.confusion_matrix(Y_digits_test, Y_pred)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(CM)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>CM_norm <span class="op">=</span> CM <span class="op">/</span> CM.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(CM_norm)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>plt.matshow(CM)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[[87  0  0  0  1  0  0  0  0  0]
 [ 0 82  5  1  0  1  0  0  0  2]
 [ 1  0 79  6  0  0  0  0  0  0]
 [ 0  0  0 81  0  3  0  4  1  2]
 [ 2  0  0  0 87  0  0  2  1  0]
 [ 0  0  0  0  0 85  3  0  0  3]
 [ 0  0  0  0  0  0 91  0  0  0]
 [ 0  0  1  0  0  0  0 88  0  0]
 [ 0  6  1  6  0  4  1  1 68  1]
 [ 1  0  0  4  0  2  0  0  1 84]]
[[0.98863636 0.         0.         0.         0.01136364 0.
  0.         0.         0.         0.        ]
 [0.         0.9010989  0.05494505 0.01098901 0.         0.01098901
  0.         0.         0.         0.02197802]
 [0.01162791 0.         0.91860465 0.06976744 0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.89010989 0.         0.03296703
  0.         0.04395604 0.01098901 0.02197802]
 [0.02173913 0.         0.         0.         0.94565217 0.
  0.         0.02173913 0.01086957 0.        ]
 [0.         0.         0.         0.         0.         0.93406593
  0.03296703 0.         0.         0.03296703]
 [0.         0.         0.         0.         0.         0.
  1.         0.         0.         0.        ]
 [0.         0.         0.01123596 0.         0.         0.
  0.         0.98876404 0.         0.        ]
 [0.         0.06818182 0.01136364 0.06818182 0.         0.04545455
  0.01136364 0.01136364 0.77272727 0.01136364]
 [0.01086957 0.         0.         0.04347826 0.         0.02173913
  0.         0.         0.01086957 0.91304348]]</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>&lt;matplotlib.image.AxesImage at 0x12e84a0d0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TP1-knn_files/figure-html/cell-12-output-3.png" width="503" height="529"></p>
</div>
</div>
<p>On obtient une matrice de confusion qui est plutôt bien. La capacité du classifieur à mettre l’image dans la bonne case est assez élevée. On remarque sur la matrice que sur la diagonale c’est assez clair, donc la probabilité est proche de 1 par rapport aux autres cases.</p>
<!-- -->

</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb19" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "TP1 - knn"</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="an">title-block-banner:</span><span class="co"> true</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co">  html:   </span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: minty</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="an">toc-depth:</span><span class="co"> 3</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="an">toc-title:</span><span class="co"> "Sommaire"</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Anne Bernard</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2023-09-14</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="fu"># Rappels de classification</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="fu">## Généralisation artificielle de données &lt;a name="Généralisation artificielle de données"&gt;&lt;/a&gt;</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="fu">### Question 1 &lt;a name="Question 1"&gt;&lt;/a&gt;</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="in">`rand_gauss`</span> :</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>La fonction <span class="in">`rand_gauss`</span> génère des points échantillonnés à partir d'une variable gaussienne de taille 2 centrée réduite. Elle prend en paramètres le nombre d'échantillons $n=100$, la moyenne $\mu=<span class="co">[</span><span class="ot">1,1</span><span class="co">]</span>$ et l'écart-type $\sigma=<span class="co">[</span><span class="ot">\sqrt{0.1},\sqrt{0.1}</span><span class="co">]</span>$. Elle retourne un tableau avec la variable gaussienne de moyenne $\mu=<span class="co">[</span><span class="ot">1,1</span><span class="co">]</span>$ et d'écart-type $\sigma=<span class="co">[</span><span class="ot">\sqrt{0.1},\sqrt{0.1}</span><span class="co">]</span>$.</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="in">`rand_bi_gauss`</span> :</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>La fonction <span class="in">`rand_bi_gauss`</span> génère grâce à <span class="in">`rand_gauss`</span> deux variables gaussiennes d'échantillons $n_1=100$ et $n_2=100$, de moyennes et d'écart-types respectifs : $\mu_1=<span class="co">[</span><span class="ot">1,1</span><span class="co">]</span>, \, \mu_2=<span class="co">[</span><span class="ot">-1,-1</span><span class="co">]</span>$, $\sigma_1=<span class="co">[</span><span class="ot">0.1,0.1</span><span class="co">]</span>=\sigma_2$. Elle crée le vecteur $y$ des réponses en empilant $n_1$ $1$ puis $n_2$ $-1$. Elle combine aussi les échantillons dans $X$. Et ensuite elle permute aléatoirement les indices et renvoie les échantillons et les réponses.  </span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a><span class="in">`rand_tri_gauss`</span> : </span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>La fonction <span class="in">`rand_tri_gauss`</span> utilise la fonction <span class="in">`rand_gauss`</span>comme précédemment pour générer les échantillons de chaque distribution. Les échantillons générés sont ensuite empilés verticalement dans la matrice X, et les réponses correspondantes sont stockées dans le vecteur y. Ensuite les indices des échantillons sont permutés de manière aléatoire, et les échantillons et les réponses sont réorganisés en fonction de ces indices avant d'être renvoyés.</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a><span class="in">`rand_clown`</span>: </span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>La fonction <span class="in">`rand_clown`</span> commence par générer des échantillons aléatoires à partir d'une distribution gaussienne en utilisant <span class="in">`np.random.randn`</span>. Les échantillons générés sont stockés dans x0, x1 et x2.</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>Ensuite, la fonction ajoute du bruit aux échantillons du premier groupe de données en multipliant x0 par lui-même et en ajoutant le bruit généré par np.random.randn(n1, 1). Le résultat est stocké dans x1.</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>Pour le deuxième groupe de données, la fonction génère deux ensembles de bruit à l'aide de np.random.randn(n2, 1) et les combine avec sigma2 pour obtenir des valeurs différentes. Ces deux ensembles de bruit sont ensuite concaténés horizontalement à l'aide de np.hstack pour obtenir x2.</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>Enfin, les échantillons des trois groupes sont empilés verticalement en utilisant np.vstack pour obtenir la matrice X. Les réponses sont générées en empilant horizontalement n1 réponses 1 suivies de n2 réponses -1. Les indices des échantillons sont permutés aléatoirement à l'aide de <span class="in">`np.random.permutation`</span>, et les échantillons et les réponses sont réorganisés en fonction de ces indices avant d'être renvoyés.</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a><span class="in">`rand_checkers`</span>: La fonction rand_checkers génère un damier aléatoire : à partir d’une distribution uniforme, on génère un damier dans la partie surpérieure droite du plan. La structure en damier n’est pas flagrante lorsque le nombre de points générés est petit mais elle devient évidente pour 1000 points.</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a><span class="co">#| input: false </span></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, ClassifierMixin</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats  <span class="co"># to use scipy.stats.mode</span></span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> neighbors</span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tp_knn_source <span class="im">import</span> (rand_gauss, rand_bi_gauss, rand_tri_gauss,</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>                               rand_checkers, rand_clown, plot_2d, ErrorCurve,</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>                               frontiere, LOOCurve)</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> rc</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a>plt.close(<span class="st">'all'</span>)</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a>rc(<span class="st">'font'</span>, <span class="op">**</span>{<span class="st">'family'</span>: <span class="st">'sans-serif'</span>, <span class="st">'sans-serif'</span>: [<span class="st">'Computer Modern Roman'</span>]})</span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {<span class="st">'axes.labelsize'</span>: <span class="dv">12</span>,</span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>          <span class="st">'font.size'</span>: <span class="dv">16</span>,</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a>          <span class="st">'legend.fontsize'</span>: <span class="dv">16</span>,</span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>          <span class="st">'text.usetex'</span>: <span class="va">False</span>,</span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a>          <span class="st">'figure.figsize'</span>: (<span class="dv">8</span>, <span class="dv">6</span>)}</span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>plt.rcParams.update(params)</span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a>sns.set_context(<span class="st">"poster"</span>)</span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a>sns.set_palette(<span class="st">"colorblind"</span>)</span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"white"</span>)</span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)  <span class="co"># fix seed globally</span></span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-78"><a href="#cb19-78" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb19-79"><a href="#cb19-79" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> [<span class="fl">1.</span>, <span class="fl">1.</span>]</span>
<span id="cb19-80"><a href="#cb19-80" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> [<span class="fl">1.</span>, <span class="fl">1.</span>]</span>
<span id="cb19-81"><a href="#cb19-81" aria-hidden="true" tabindex="-1"></a>rand_gauss(n, mu, sigma)</span>
<span id="cb19-82"><a href="#cb19-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-83"><a href="#cb19-83" aria-hidden="true" tabindex="-1"></a>n1 <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb19-84"><a href="#cb19-84" aria-hidden="true" tabindex="-1"></a>n2 <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb19-85"><a href="#cb19-85" aria-hidden="true" tabindex="-1"></a>mu1 <span class="op">=</span> [<span class="fl">1.</span>, <span class="fl">1.</span>]</span>
<span id="cb19-86"><a href="#cb19-86" aria-hidden="true" tabindex="-1"></a>mu2 <span class="op">=</span> [<span class="op">-</span><span class="fl">1.</span>, <span class="op">-</span><span class="fl">1.</span>]</span>
<span id="cb19-87"><a href="#cb19-87" aria-hidden="true" tabindex="-1"></a>sigma1 <span class="op">=</span> [<span class="fl">0.9</span>, <span class="fl">0.9</span>]</span>
<span id="cb19-88"><a href="#cb19-88" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="op">=</span> [<span class="fl">0.9</span>, <span class="fl">0.9</span>]</span>
<span id="cb19-89"><a href="#cb19-89" aria-hidden="true" tabindex="-1"></a>X1, y1 <span class="op">=</span> rand_bi_gauss(n1, n2, mu1, mu2, sigma1, sigma2)</span>
<span id="cb19-90"><a href="#cb19-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-91"><a href="#cb19-91" aria-hidden="true" tabindex="-1"></a>n1 <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb19-92"><a href="#cb19-92" aria-hidden="true" tabindex="-1"></a>n2 <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb19-93"><a href="#cb19-93" aria-hidden="true" tabindex="-1"></a>n3 <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb19-94"><a href="#cb19-94" aria-hidden="true" tabindex="-1"></a>mu1 <span class="op">=</span> [<span class="fl">1.</span>, <span class="fl">1.</span>]</span>
<span id="cb19-95"><a href="#cb19-95" aria-hidden="true" tabindex="-1"></a>mu2 <span class="op">=</span> [<span class="op">-</span><span class="fl">1.</span>, <span class="op">-</span><span class="fl">1.</span>]</span>
<span id="cb19-96"><a href="#cb19-96" aria-hidden="true" tabindex="-1"></a>mu3 <span class="op">=</span> [<span class="fl">1.</span>, <span class="op">-</span><span class="fl">1.</span>]</span>
<span id="cb19-97"><a href="#cb19-97" aria-hidden="true" tabindex="-1"></a>sigma1 <span class="op">=</span> [<span class="fl">0.9</span>, <span class="fl">0.9</span>]</span>
<span id="cb19-98"><a href="#cb19-98" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="op">=</span> [<span class="fl">0.9</span>, <span class="fl">0.9</span>]</span>
<span id="cb19-99"><a href="#cb19-99" aria-hidden="true" tabindex="-1"></a>sigma3 <span class="op">=</span> [<span class="fl">0.9</span>, <span class="fl">0.9</span>]</span>
<span id="cb19-100"><a href="#cb19-100" aria-hidden="true" tabindex="-1"></a>X2, y2 <span class="op">=</span> rand_tri_gauss(n1, n2, n3, mu1, mu2, mu3, sigma1, sigma2, sigma3)</span>
<span id="cb19-101"><a href="#cb19-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-102"><a href="#cb19-102" aria-hidden="true" tabindex="-1"></a>n1 <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb19-103"><a href="#cb19-103" aria-hidden="true" tabindex="-1"></a>n2 <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb19-104"><a href="#cb19-104" aria-hidden="true" tabindex="-1"></a>sigma1 <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb19-105"><a href="#cb19-105" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb19-106"><a href="#cb19-106" aria-hidden="true" tabindex="-1"></a>X3, y3 <span class="op">=</span> rand_clown(n1, n2, sigma1, sigma2)</span>
<span id="cb19-107"><a href="#cb19-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-108"><a href="#cb19-108" aria-hidden="true" tabindex="-1"></a>n1 <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb19-109"><a href="#cb19-109" aria-hidden="true" tabindex="-1"></a>n2 <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb19-110"><a href="#cb19-110" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb19-111"><a href="#cb19-111" aria-hidden="true" tabindex="-1"></a>X4, y4 <span class="op">=</span> rand_checkers(n1, n2, sigma)</span>
<span id="cb19-112"><a href="#cb19-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-113"><a href="#cb19-113" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb19-114"><a href="#cb19-114" aria-hidden="true" tabindex="-1"></a>plt.close(<span class="st">"all"</span>)</span>
<span id="cb19-115"><a href="#cb19-115" aria-hidden="true" tabindex="-1"></a>plt.ion()</span>
<span id="cb19-116"><a href="#cb19-116" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb19-117"><a href="#cb19-117" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">141</span>)</span>
<span id="cb19-118"><a href="#cb19-118" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'First data set'</span>)</span>
<span id="cb19-119"><a href="#cb19-119" aria-hidden="true" tabindex="-1"></a>plot_2d(X1, y1)</span>
<span id="cb19-120"><a href="#cb19-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-121"><a href="#cb19-121" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">142</span>)</span>
<span id="cb19-122"><a href="#cb19-122" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Second data set'</span>)</span>
<span id="cb19-123"><a href="#cb19-123" aria-hidden="true" tabindex="-1"></a>plot_2d(X2, y2)</span>
<span id="cb19-124"><a href="#cb19-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-125"><a href="#cb19-125" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">143</span>)</span>
<span id="cb19-126"><a href="#cb19-126" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Third data set'</span>)</span>
<span id="cb19-127"><a href="#cb19-127" aria-hidden="true" tabindex="-1"></a>plot_2d(X3, y3)</span>
<span id="cb19-128"><a href="#cb19-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-129"><a href="#cb19-129" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">144</span>)</span>
<span id="cb19-130"><a href="#cb19-130" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Fourth data set'</span>)</span>
<span id="cb19-131"><a href="#cb19-131" aria-hidden="true" tabindex="-1"></a>plot_2d(X4, y4)</span>
<span id="cb19-132"><a href="#cb19-132" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-133"><a href="#cb19-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-134"><a href="#cb19-134" aria-hidden="true" tabindex="-1"></a><span class="fu"># La méthode des k-plus prohces voisins</span></span>
<span id="cb19-135"><a href="#cb19-135" aria-hidden="true" tabindex="-1"></a><span class="fu">## Approche intuitive </span></span>
<span id="cb19-136"><a href="#cb19-136" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;a</span> <span class="er">name</span><span class="ot">=</span><span class="st">"Approche intuitive"</span><span class="kw">&gt;&lt;/a&gt;</span></span>
<span id="cb19-137"><a href="#cb19-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-138"><a href="#cb19-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-139"><a href="#cb19-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-140"><a href="#cb19-140" aria-hidden="true" tabindex="-1"></a><span class="fu">### Question 1</span></span>
<span id="cb19-141"><a href="#cb19-141" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;a</span> <span class="er">name</span><span class="ot">=</span><span class="st">"Question 1"</span><span class="kw">&gt;&lt;/a&gt;</span></span>
<span id="cb19-142"><a href="#cb19-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-143"><a href="#cb19-143" aria-hidden="true" tabindex="-1"></a>La méthode que l'on pourrait utiliser est la suivante : on pourrait faire la moyenne des k plus proches voisins pour obtenir une valeur approchée de notre point, bien que nous ne pourrions pas tomber sur la valeur exacte. Ce n'est pas aussi 'simple' qu'avec des classes de nombres entiers.</span>
<span id="cb19-144"><a href="#cb19-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-145"><a href="#cb19-145" aria-hidden="true" tabindex="-1"></a><span class="fu">## Approche formelle</span></span>
<span id="cb19-146"><a href="#cb19-146" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;a</span> <span class="er">name</span><span class="ot">=</span><span class="st">"Approche formelle"</span><span class="kw">&gt;&lt;/a&gt;</span></span>
<span id="cb19-147"><a href="#cb19-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-148"><a href="#cb19-148" aria-hidden="true" tabindex="-1"></a><span class="fu">### Question 2</span></span>
<span id="cb19-149"><a href="#cb19-149" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;a</span> <span class="er">name</span><span class="ot">=</span><span class="st">"Question 2"</span><span class="kw">&gt;&lt;/a&gt;</span></span>
<span id="cb19-150"><a href="#cb19-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-153"><a href="#cb19-153" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-154"><a href="#cb19-154" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> KNNClassifier(BaseEstimator, ClassifierMixin):</span>
<span id="cb19-155"><a href="#cb19-155" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Home made KNN Classifier class."""</span></span>
<span id="cb19-156"><a href="#cb19-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-157"><a href="#cb19-157" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_neighbors<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb19-158"><a href="#cb19-158" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_neighbors <span class="op">=</span> n_neighbors</span>
<span id="cb19-159"><a href="#cb19-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-160"><a href="#cb19-160" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb19-161"><a href="#cb19-161" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_ <span class="op">=</span> X</span>
<span id="cb19-162"><a href="#cb19-162" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_ <span class="op">=</span> y</span>
<span id="cb19-163"><a href="#cb19-163" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb19-164"><a href="#cb19-164" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sauvegarde les données d'entrainement</span></span>
<span id="cb19-165"><a href="#cb19-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-166"><a href="#cb19-166" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb19-167"><a href="#cb19-167" aria-hidden="true" tabindex="-1"></a>        dist <span class="op">=</span> np.<span class="bu">sum</span>((X[:, np.newaxis, :]<span class="op">-</span><span class="va">self</span>.X_[np.newaxis, :, :])<span class="op">**</span><span class="dv">2</span>,</span>
<span id="cb19-168"><a href="#cb19-168" aria-hidden="true" tabindex="-1"></a>                      axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb19-169"><a href="#cb19-169" aria-hidden="true" tabindex="-1"></a>        idx_sort <span class="op">=</span> np.argsort(dist, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-170"><a href="#cb19-170" aria-hidden="true" tabindex="-1"></a>        <span class="co"># on récupère les indices par rapport aux valeurs des distances</span></span>
<span id="cb19-171"><a href="#cb19-171" aria-hidden="true" tabindex="-1"></a>        idx_neighbors <span class="op">=</span> idx_sort[:, :<span class="va">self</span>.n_neighbors]</span>
<span id="cb19-172"><a href="#cb19-172" aria-hidden="true" tabindex="-1"></a>        y_neighbors <span class="op">=</span> <span class="va">self</span>.y_[idx_neighbors]</span>
<span id="cb19-173"><a href="#cb19-173" aria-hidden="true" tabindex="-1"></a>        <span class="co"># on trouve les labels des voisins</span></span>
<span id="cb19-174"><a href="#cb19-174" aria-hidden="true" tabindex="-1"></a>        mode, _ <span class="op">=</span> stats.mode(y_neighbors, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-175"><a href="#cb19-175" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> np.asarray(mode.ravel(), dtype<span class="op">=</span>np.intp)</span>
<span id="cb19-176"><a href="#cb19-176" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> y_pred</span>
<span id="cb19-177"><a href="#cb19-177" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-178"><a href="#cb19-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-179"><a href="#cb19-179" aria-hidden="true" tabindex="-1"></a>Après avoir compléter le code, nous pouvons vérifier si cette méthode est identique ou non à celle de <span class="in">`scikit-learn`</span>.</span>
<span id="cb19-180"><a href="#cb19-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-183"><a href="#cb19-183" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-184"><a href="#cb19-184" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X2[::<span class="dv">2</span>]</span>
<span id="cb19-185"><a href="#cb19-185" aria-hidden="true" tabindex="-1"></a>Y_train <span class="op">=</span> y2[::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb19-186"><a href="#cb19-186" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X2[<span class="dv">1</span>::<span class="dv">2</span>]</span>
<span id="cb19-187"><a href="#cb19-187" aria-hidden="true" tabindex="-1"></a>Y_test <span class="op">=</span> y2[<span class="dv">1</span>::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb19-188"><a href="#cb19-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-189"><a href="#cb19-189" aria-hidden="true" tabindex="-1"></a><span class="co"># on utilise la classe KNNClassifier avec 10 voisins</span></span>
<span id="cb19-190"><a href="#cb19-190" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> KNNClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb19-191"><a href="#cb19-191" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, Y_train)</span>
<span id="cb19-192"><a href="#cb19-192" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb19-193"><a href="#cb19-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-194"><a href="#cb19-194" aria-hidden="true" tabindex="-1"></a><span class="co"># on utilise la classe KNeighborsClassifier avec 10 voisins</span></span>
<span id="cb19-195"><a href="#cb19-195" aria-hidden="true" tabindex="-1"></a>knn2 <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb19-196"><a href="#cb19-196" aria-hidden="true" tabindex="-1"></a>knn2.fit(X_train, Y_train)</span>
<span id="cb19-197"><a href="#cb19-197" aria-hidden="true" tabindex="-1"></a>y_pred2 <span class="op">=</span> knn2.predict(X_test)</span>
<span id="cb19-198"><a href="#cb19-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-199"><a href="#cb19-199" aria-hidden="true" tabindex="-1"></a><span class="co"># comparaison des deux</span></span>
<span id="cb19-200"><a href="#cb19-200" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(metrics.accuracy_score(Y_test, y_pred))</span>
<span id="cb19-201"><a href="#cb19-201" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(metrics.accuracy_score(Y_test, y_pred2))</span>
<span id="cb19-202"><a href="#cb19-202" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-203"><a href="#cb19-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-204"><a href="#cb19-204" aria-hidden="true" tabindex="-1"></a>Les résultats de précisions sont les mêmes pour les deux classes donc elles sont équivalentes.</span>
<span id="cb19-205"><a href="#cb19-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-206"><a href="#cb19-206" aria-hidden="true" tabindex="-1"></a><span class="fu">### Question 3</span></span>
<span id="cb19-207"><a href="#cb19-207" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;a</span> <span class="er">name</span><span class="ot">=</span><span class="st">"Question 3"</span><span class="kw">&gt;&lt;/a&gt;</span></span>
<span id="cb19-208"><a href="#cb19-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-209"><a href="#cb19-209" aria-hidden="true" tabindex="-1"></a>En utilisant la méthode de <span class="in">`scikit-learn`</span>, nous allons comparer 3 jeux de données, avec la distance euclidienne $d(x,v)=||x-v||^2$</span>
<span id="cb19-210"><a href="#cb19-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-213"><a href="#cb19-213" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-214"><a href="#cb19-214" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false </span></span>
<span id="cb19-215"><a href="#cb19-215" aria-hidden="true" tabindex="-1"></a>n_neighbors <span class="op">=</span> <span class="dv">5</span>  <span class="co"># the k in k-NN</span></span>
<span id="cb19-216"><a href="#cb19-216" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span>n_neighbors)</span>
<span id="cb19-217"><a href="#cb19-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-218"><a href="#cb19-218" aria-hidden="true" tabindex="-1"></a><span class="co"># for data in [data1, data2, data3, data4]:</span></span>
<span id="cb19-219"><a href="#cb19-219" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> X, y <span class="kw">in</span> [(X1, y1), (X2, y2), (X3, y3), (X4, y4)]:</span>
<span id="cb19-220"><a href="#cb19-220" aria-hidden="true" tabindex="-1"></a>    knn.fit(X, y)</span>
<span id="cb19-221"><a href="#cb19-221" aria-hidden="true" tabindex="-1"></a>    plt.figure()</span>
<span id="cb19-222"><a href="#cb19-222" aria-hidden="true" tabindex="-1"></a>    n_labels <span class="op">=</span> np.unique(y).shape[<span class="dv">0</span>]</span>
<span id="cb19-223"><a href="#cb19-223" aria-hidden="true" tabindex="-1"></a>    frontiere(knn, X, y, w<span class="op">=</span><span class="va">None</span>, step<span class="op">=</span><span class="dv">50</span>, alpha_choice<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb19-224"><a href="#cb19-224" aria-hidden="true" tabindex="-1"></a>              n_labels<span class="op">=</span>n_labels, n_neighbors<span class="op">=</span>n_neighbors)</span>
<span id="cb19-225"><a href="#cb19-225" aria-hidden="true" tabindex="-1"></a>    plt.draw()</span>
<span id="cb19-226"><a href="#cb19-226" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-227"><a href="#cb19-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-228"><a href="#cb19-228" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;figure</span> <span class="er">style</span><span class="ot">=</span><span class="st">"center"</span><span class="kw">&gt;</span></span>
<span id="cb19-229"><a href="#cb19-229" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;img</span> <span class="er">src</span><span class="ot">=</span><span class="st">"image/output1.png"</span> <span class="er">width</span><span class="ot">=</span><span class="st">'500'</span> <span class="er">height</span><span class="ot">=</span><span class="st">'450'</span><span class="kw">&gt;</span></span>
<span id="cb19-230"><a href="#cb19-230" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;img</span> <span class="er">src</span><span class="ot">=</span><span class="st">"image/output2.png"</span> <span class="er">width</span><span class="ot">=</span><span class="st">'500'</span> <span class="er">height</span><span class="ot">=</span><span class="st">'450'</span><span class="kw">&gt;</span></span>
<span id="cb19-231"><a href="#cb19-231" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;img</span> <span class="er">src</span><span class="ot">=</span><span class="st">"image/output3.png"</span> <span class="er">width</span><span class="ot">=</span><span class="st">'500'</span> <span class="er">height</span><span class="ot">=</span><span class="st">'450'</span><span class="kw">&gt;</span></span>
<span id="cb19-232"><a href="#cb19-232" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&lt;img</span> <span class="er">src</span><span class="ot">=</span><span class="st">"image/output4.png"</span> <span class="er">width</span><span class="ot">=</span><span class="st">'500'</span> <span class="er">height</span><span class="ot">=</span><span class="st">'450'</span><span class="kw">&gt;</span></span>
<span id="cb19-233"><a href="#cb19-233" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/figure&gt;</span></span>
<span id="cb19-234"><a href="#cb19-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-235"><a href="#cb19-235" aria-hidden="true" tabindex="-1"></a><span class="fu">### Question 4</span></span>
<span id="cb19-236"><a href="#cb19-236" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;a</span> <span class="er">name</span><span class="ot">=</span><span class="st">"Question 4"</span><span class="kw">&gt;&lt;/a&gt;</span></span>
<span id="cb19-237"><a href="#cb19-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-240"><a href="#cb19-240" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-241"><a href="#cb19-241" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb19-242"><a href="#cb19-242" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">3</span>)</span>
<span id="cb19-243"><a href="#cb19-243" aria-hidden="true" tabindex="-1"></a>plot_2d(X_train, Y_train)</span>
<span id="cb19-244"><a href="#cb19-244" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Samples'</span>)</span>
<span id="cb19-245"><a href="#cb19-245" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> plt.gca()</span>
<span id="cb19-246"><a href="#cb19-246" aria-hidden="true" tabindex="-1"></a>ax.get_yaxis().set_ticks([])</span>
<span id="cb19-247"><a href="#cb19-247" aria-hidden="true" tabindex="-1"></a>ax.get_xaxis().set_ticks([])</span>
<span id="cb19-248"><a href="#cb19-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-249"><a href="#cb19-249" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_neighbors <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>):</span>
<span id="cb19-250"><a href="#cb19-250" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co"> : fit the knn</span></span>
<span id="cb19-251"><a href="#cb19-251" aria-hidden="true" tabindex="-1"></a>    knn <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span>n_neighbors)</span>
<span id="cb19-252"><a href="#cb19-252" aria-hidden="true" tabindex="-1"></a>    knn.fit(X_train, Y_train)</span>
<span id="cb19-253"><a href="#cb19-253" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">5</span> <span class="op">+</span> n_neighbors)</span>
<span id="cb19-254"><a href="#cb19-254" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'KNN with k=</span><span class="sc">%d</span><span class="st">'</span> <span class="op">%</span> n_neighbors)</span>
<span id="cb19-255"><a href="#cb19-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-256"><a href="#cb19-256" aria-hidden="true" tabindex="-1"></a>    n_labels <span class="op">=</span> np.unique(y).shape[<span class="dv">0</span>]</span>
<span id="cb19-257"><a href="#cb19-257" aria-hidden="true" tabindex="-1"></a>    frontiere(knn, X, y, w<span class="op">=</span><span class="va">None</span>, step<span class="op">=</span><span class="dv">50</span>, alpha_choice<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb19-258"><a href="#cb19-258" aria-hidden="true" tabindex="-1"></a>              n_labels<span class="op">=</span>n_labels, colorbar<span class="op">=</span><span class="va">False</span>, samples<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb19-259"><a href="#cb19-259" aria-hidden="true" tabindex="-1"></a>              n_neighbors<span class="op">=</span>n_neighbors)</span>
<span id="cb19-260"><a href="#cb19-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-261"><a href="#cb19-261" aria-hidden="true" tabindex="-1"></a>plt.draw()  <span class="co"># update plot</span></span>
<span id="cb19-262"><a href="#cb19-262" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-263"><a href="#cb19-263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-264"><a href="#cb19-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-265"><a href="#cb19-265" aria-hidden="true" tabindex="-1"></a>Lorsque l'on modifie les valeurs de $k$ on s'aperçoit d'un changement important. En effet, plus le nombre de voisins est important plus les frontières sont nettes et simples. Lorsque $k=1$ la frontière est très complexe, en effet le classifieur est sensible au bruit, il ne se base que sur le plus proche et donc n'est pas fiable. Il surapprend. Si le nombre est trop grand, par exemple si $k=n$, on va utiliser tous les points et donc le classifieur n'apporte aucune information, une seule classe sera donnée pour chaque point (la classe la plus nombreuse).</span>
<span id="cb19-266"><a href="#cb19-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-267"><a href="#cb19-267" aria-hidden="true" tabindex="-1"></a><span class="fu">### Question 5</span></span>
<span id="cb19-268"><a href="#cb19-268" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;a</span> <span class="er">name</span><span class="ot">=</span><span class="st">"Question 5"</span><span class="kw">&gt;&lt;/a&gt;</span></span>
<span id="cb19-269"><a href="#cb19-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-272"><a href="#cb19-272" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-273"><a href="#cb19-273" aria-hidden="true" tabindex="-1"></a><span class="co"># taux d'erreur sur les données d'apprentissage</span></span>
<span id="cb19-274"><a href="#cb19-274" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X2[::<span class="dv">2</span>]</span>
<span id="cb19-275"><a href="#cb19-275" aria-hidden="true" tabindex="-1"></a>Y_train <span class="op">=</span> y2[::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb19-276"><a href="#cb19-276" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X2[<span class="dv">1</span>::<span class="dv">2</span>]</span>
<span id="cb19-277"><a href="#cb19-277" aria-hidden="true" tabindex="-1"></a>Y_test <span class="op">=</span> y2[<span class="dv">1</span>::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb19-278"><a href="#cb19-278" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-279"><a href="#cb19-279" aria-hidden="true" tabindex="-1"></a>knn.fit(X_train, Y_train)</span>
<span id="cb19-280"><a href="#cb19-280" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> knn.predict(X_train)</span>
<span id="cb19-281"><a href="#cb19-281" aria-hidden="true" tabindex="-1"></a>y_predtest <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb19-282"><a href="#cb19-282" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="dv">1</span><span class="op">-</span>metrics.accuracy_score(Y_train, y_pred))</span>
<span id="cb19-283"><a href="#cb19-283" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="dv">1</span><span class="op">-</span>metrics.accuracy_score(Y_test, y_predtest))</span>
<span id="cb19-284"><a href="#cb19-284" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-285"><a href="#cb19-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-286"><a href="#cb19-286" aria-hidden="true" tabindex="-1"></a>On remarque que le taux d'erreur sur les données d'apprentissage lorsque $k=1$ est nul. C'est normal car l'on prend le plus proche voisin du point qui est lui-même donc on trouve la bonne classe. </span>
<span id="cb19-287"><a href="#cb19-287" aria-hidden="true" tabindex="-1"></a>Le taux d'erreur sur les données de test lorsque $k=1$ est d'environ $0.19$ ce qui peut être amélioré. En effet lorsqu'on prend juste un voisin pour tester un point il est quand même probable que le plus proche ne soit pas de la même classe. Ce n'est pas assez significatif, il faut prendre plus de voisins.</span>
<span id="cb19-288"><a href="#cb19-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-289"><a href="#cb19-289" aria-hidden="true" tabindex="-1"></a>On peut également utiliser la fonction <span class="in">`.score`</span> de <span class="in">`scikit-learn`</span> : <span class="in">`1-knn.score(X_train, Y_train)`</span> pour les données d'entrainements. On obtient les mêmes résultats.</span>
<span id="cb19-290"><a href="#cb19-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-291"><a href="#cb19-291" aria-hidden="true" tabindex="-1"></a><span class="fu">### Question 6</span></span>
<span id="cb19-292"><a href="#cb19-292" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;a</span> <span class="er">name</span><span class="ot">=</span><span class="st">"Question 6"</span><span class="kw">&gt;&lt;/a&gt;</span></span>
<span id="cb19-293"><a href="#cb19-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-296"><a href="#cb19-296" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-297"><a href="#cb19-297" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> (<span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>)</span>
<span id="cb19-298"><a href="#cb19-298" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> []</span>
<span id="cb19-299"><a href="#cb19-299" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> N:</span>
<span id="cb19-300"><a href="#cb19-300" aria-hidden="true" tabindex="-1"></a>  sigma <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb19-301"><a href="#cb19-301" aria-hidden="true" tabindex="-1"></a>  data4, rep4 <span class="op">=</span> rand_checkers(i, i, sigma)</span>
<span id="cb19-302"><a href="#cb19-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-303"><a href="#cb19-303" aria-hidden="true" tabindex="-1"></a>  X_train <span class="op">=</span> data4[::<span class="dv">2</span>]</span>
<span id="cb19-304"><a href="#cb19-304" aria-hidden="true" tabindex="-1"></a>  Y_train <span class="op">=</span> rep4[::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb19-305"><a href="#cb19-305" aria-hidden="true" tabindex="-1"></a>  X_test <span class="op">=</span> data4[<span class="dv">1</span>::<span class="dv">2</span>]</span>
<span id="cb19-306"><a href="#cb19-306" aria-hidden="true" tabindex="-1"></a>  Y_test <span class="op">=</span> rep4[<span class="dv">1</span>::<span class="dv">2</span>].astype(<span class="bu">int</span>)</span>
<span id="cb19-307"><a href="#cb19-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-308"><a href="#cb19-308" aria-hidden="true" tabindex="-1"></a>  EC <span class="op">=</span> ErrorCurve(k_range<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">50</span>, <span class="dv">1</span>)))</span>
<span id="cb19-309"><a href="#cb19-309" aria-hidden="true" tabindex="-1"></a>  EC.fit_curve(X_train, Y_train, X_test, Y_test)</span>
<span id="cb19-310"><a href="#cb19-310" aria-hidden="true" tabindex="-1"></a>  EC.plot()</span>
<span id="cb19-311"><a href="#cb19-311" aria-hidden="true" tabindex="-1"></a>  kmin <span class="op">=</span> np.argmin(EC.errors)<span class="op">+</span><span class="dv">1</span></span>
<span id="cb19-312"><a href="#cb19-312" aria-hidden="true" tabindex="-1"></a>  K.append(kmin)</span>
<span id="cb19-313"><a href="#cb19-313" aria-hidden="true" tabindex="-1"></a>K</span>
<span id="cb19-314"><a href="#cb19-314" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-315"><a href="#cb19-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-316"><a href="#cb19-316" aria-hidden="true" tabindex="-1"></a>On obtient des valeurs de $k$ différentes. </span>
<span id="cb19-317"><a href="#cb19-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-318"><a href="#cb19-318" aria-hidden="true" tabindex="-1"></a><span class="fu">### Question 7</span></span>
<span id="cb19-319"><a href="#cb19-319" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;a</span> <span class="er">name</span><span class="ot">=</span><span class="st">"Question 7"</span><span class="kw">&gt;&lt;/a&gt;</span></span>
<span id="cb19-320"><a href="#cb19-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-321"><a href="#cb19-321" aria-hidden="true" tabindex="-1"></a>C'est plutôt long en temps de calcul car il faut calculer les distances pour chaque point. En grande dimension, les points sont de plus en plus loin et donc ils ne sont plus tellement "voisins".</span>
<span id="cb19-322"><a href="#cb19-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-323"><a href="#cb19-323" aria-hidden="true" tabindex="-1"></a><span class="fu">### Question 8</span></span>
<span id="cb19-324"><a href="#cb19-324" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;a</span> <span class="er">name</span><span class="ot">=</span><span class="st">"Question 8"</span><span class="kw">&gt;&lt;/a&gt;</span></span>
<span id="cb19-325"><a href="#cb19-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-328"><a href="#cb19-328" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-329"><a href="#cb19-329" aria-hidden="true" tabindex="-1"></a><span class="co"># The digits dataset</span></span>
<span id="cb19-330"><a href="#cb19-330" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> datasets.load_digits()</span>
<span id="cb19-331"><a href="#cb19-331" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(digits))</span>
<span id="cb19-332"><a href="#cb19-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-333"><a href="#cb19-333" aria-hidden="true" tabindex="-1"></a><span class="co"># plot some images to observe the data</span></span>
<span id="cb19-334"><a href="#cb19-334" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb19-335"><a href="#cb19-335" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index, (img, label) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">list</span>(<span class="bu">zip</span>(digits.images, digits.target))</span>
<span id="cb19-336"><a href="#cb19-336" aria-hidden="true" tabindex="-1"></a>                                     [<span class="dv">10</span>:<span class="dv">20</span>]):</span>
<span id="cb19-337"><a href="#cb19-337" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>, index <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb19-338"><a href="#cb19-338" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb19-339"><a href="#cb19-339" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img, cmap<span class="op">=</span>plt.cm.gray_r, interpolation<span class="op">=</span><span class="st">'None'</span>)</span>
<span id="cb19-340"><a href="#cb19-340" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'</span><span class="sc">%i</span><span class="st">'</span> <span class="op">%</span> label)</span>
<span id="cb19-341"><a href="#cb19-341" aria-hidden="true" tabindex="-1"></a>plt.draw()</span>
<span id="cb19-342"><a href="#cb19-342" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-343"><a href="#cb19-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-344"><a href="#cb19-344" aria-hidden="true" tabindex="-1"></a>On regarde les images du dataset. Il s'agit d'images de chiffres de 0 à 9 très pixellisés. </span>
<span id="cb19-345"><a href="#cb19-345" aria-hidden="true" tabindex="-1"></a>On applique ensuite la méthode vue précédemment pour classifier ces images.</span>
<span id="cb19-346"><a href="#cb19-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-349"><a href="#cb19-349" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-350"><a href="#cb19-350" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="bu">len</span>(digits.data)</span>
<span id="cb19-351"><a href="#cb19-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-352"><a href="#cb19-352" aria-hidden="true" tabindex="-1"></a>X_digits_train <span class="op">=</span> digits.data[:n_samples <span class="op">//</span> <span class="dv">2</span>]</span>
<span id="cb19-353"><a href="#cb19-353" aria-hidden="true" tabindex="-1"></a>Y_digits_train <span class="op">=</span> digits.target[:n_samples <span class="op">//</span> <span class="dv">2</span>]</span>
<span id="cb19-354"><a href="#cb19-354" aria-hidden="true" tabindex="-1"></a>X_digits_test <span class="op">=</span> digits.data[n_samples <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb19-355"><a href="#cb19-355" aria-hidden="true" tabindex="-1"></a>Y_digits_test <span class="op">=</span> digits.target[n_samples <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb19-356"><a href="#cb19-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-357"><a href="#cb19-357" aria-hidden="true" tabindex="-1"></a>knn <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb19-358"><a href="#cb19-358" aria-hidden="true" tabindex="-1"></a>knn.fit(X_digits_train, Y_digits_train)</span>
<span id="cb19-359"><a href="#cb19-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-360"><a href="#cb19-360" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> knn.score(X_digits_test, Y_digits_test)</span>
<span id="cb19-361"><a href="#cb19-361" aria-hidden="true" tabindex="-1"></a>Y_digits_pred <span class="op">=</span> knn.predict(X_digits_test)</span>
<span id="cb19-362"><a href="#cb19-362" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Score : </span><span class="sc">%s</span><span class="st">'</span> <span class="op">%</span> score)</span>
<span id="cb19-363"><a href="#cb19-363" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-364"><a href="#cb19-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-365"><a href="#cb19-365" aria-hidden="true" tabindex="-1"></a>Après avoir classifier grâce à <span class="in">`scikit-learn`</span>, on obtient une précision assez élevé de $0.925$. On a donc à peine $8\%$ d'erreur.</span>
<span id="cb19-366"><a href="#cb19-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-367"><a href="#cb19-367" aria-hidden="true" tabindex="-1"></a><span class="fu">### Question 9</span></span>
<span id="cb19-368"><a href="#cb19-368" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;a</span> <span class="er">name</span><span class="ot">=</span><span class="st">"Question 9"</span><span class="kw">&gt;&lt;/a&gt;</span></span>
<span id="cb19-369"><a href="#cb19-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-370"><a href="#cb19-370" aria-hidden="true" tabindex="-1"></a>Soit $(\mathbb{P}<span class="sc">\{</span>Y=i, C_k(X)=j<span class="sc">\}</span>)_{i,j}$ est la matrice de confusion associée au classifieur $C_k$ obtenu. </span>
<span id="cb19-371"><a href="#cb19-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-374"><a href="#cb19-374" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-375"><a href="#cb19-375" aria-hidden="true" tabindex="-1"></a>X_digits_train <span class="op">=</span> digits.data[:n_samples <span class="op">//</span> <span class="dv">2</span>]</span>
<span id="cb19-376"><a href="#cb19-376" aria-hidden="true" tabindex="-1"></a>Y_digits_train <span class="op">=</span> digits.target[:n_samples <span class="op">//</span> <span class="dv">2</span>]</span>
<span id="cb19-377"><a href="#cb19-377" aria-hidden="true" tabindex="-1"></a>X_digits_test <span class="op">=</span> digits.data[n_samples <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb19-378"><a href="#cb19-378" aria-hidden="true" tabindex="-1"></a>Y_digits_test <span class="op">=</span> digits.target[n_samples <span class="op">//</span> <span class="dv">2</span>:]</span>
<span id="cb19-379"><a href="#cb19-379" aria-hidden="true" tabindex="-1"></a>knn.fit(X_digits_train, Y_digits_train)</span>
<span id="cb19-380"><a href="#cb19-380" aria-hidden="true" tabindex="-1"></a>Y_pred <span class="op">=</span> knn.predict(X_digits_test)</span>
<span id="cb19-381"><a href="#cb19-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-382"><a href="#cb19-382" aria-hidden="true" tabindex="-1"></a>CM <span class="op">=</span> metrics.confusion_matrix(Y_digits_test, Y_pred)</span>
<span id="cb19-383"><a href="#cb19-383" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(CM)</span>
<span id="cb19-384"><a href="#cb19-384" aria-hidden="true" tabindex="-1"></a>CM_norm <span class="op">=</span> CM <span class="op">/</span> CM.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb19-385"><a href="#cb19-385" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(CM_norm)</span>
<span id="cb19-386"><a href="#cb19-386" aria-hidden="true" tabindex="-1"></a>plt.matshow(CM)</span>
<span id="cb19-387"><a href="#cb19-387" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb19-388"><a href="#cb19-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-389"><a href="#cb19-389" aria-hidden="true" tabindex="-1"></a>On obtient une matrice de confusion qui est plutôt bien. La capacité du classifieur à mettre l'image dans la bonne case est assez élevée. On remarque sur la matrice que sur la diagonale c'est assez clair, donc la probabilité est proche de 1 par rapport aux autres cases. </span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>